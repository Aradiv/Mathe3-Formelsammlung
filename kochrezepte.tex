%% This is file uses
%% TUDa-CI -- Corporate Design for TU Darmstadt
%% ----------------------------------------------------------------------------
%%
%%  Copyright (C) 2018--2021 by Marei Peischl <marei@peitex.de>
%%
%% ============================================================================
%% This work may be distributed and/or modified under the
%% conditions of the LaTeX Project Public License, either version 1.3c
%% of this license or (at your option) any later version.
%% The latest version of this license is in
%% http://www.latex-project.org/lppl.txt
%% and version 1.3c or later is part of all distributions of LaTeX
%% version 2008/05/04 or later.
%%
%% This work has the LPPL maintenance status `maintained'.
%%
%% The Current Maintainers of this work are
%%   Marei Peischl <tuda-ci@peitex.de>
%%   Markus Lazanowski <latex@ce.tu-darmstadt.de>
%%
%% The development respository can be found at
%% https://github.com/tudace/tuda_latex_templates
%% Please use the issue tracker for feedback!
%%
%% If you need a compiled version of this document, have a look at
%% http://mirror.ctan.org/macros/latex/contrib/tuda-ci/doc
%% or at the documentation directory of this package (if installed)
%% <path to your LaTeX distribution>/doc/latex/tuda-ci
%% ============================================================================
%%
% !TeX program = lualatex
%%

%! Author = stef9998

% Preamble
\documentclass[
%11pt
ngerman,
accentcolor=9c,% Farbe für Hervorhebungen auf Basis der Deklarationen in den
type=intern,
marginpar=false
]{tudapub}

% Packages
\usepackage[english, main=ngerman]{babel}
\usepackage[autostyle]{csquotes}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz}
\usetikzlibrary{tikzmark,calc}
%\usepackage{graphicx}
%\usepackage{amsfonts}
%\usepackage{enumitem}
%\usepackage{mathtools}
%\usepackage{mathrsfs}

% Document
\begin{document}
%    \newtheorem{satz}{Satz}[section]
%    \numberwithin{satz}{subsection}
%    \newtheorem{korolar}[satz]{Korolar}
%    \newtheorem{definition}[satz]{Definition}

    \title{Mathe 3Inf/4Etit Kochrezepte}
    \author{Stef9998}
%    \date{} % Ohne Angabe wird automatisch das heutige Datum eingefügt

    \maketitle
    \tableofcontents
    \newpage

    \section{Interpolation}
        \subsection{Polynominterpolation (Newtonsche Interpolationsformel)}
            Wir berechnen ein Polynom $n$-ten Grades $p_n(x)$ welches die Ursprungsfunktion annähert.\\
            \\
            Dafür benutzen wir das Schema
            \begin{center}
                \begin{tabular}{c | c c c}
                    $x_0$   & $f_{[x_0]} = y_0$ \tikzmark{0}  &                  & \\
                    &                   & \tikzmark{01l} $f_{[x_0,x_1]}$ \tikzmark{01r} & \\
                    $x_1$   & $f_{[x_1]} = y_1$ \tikzmark{1}  &                  & \tikzmark{012}$f_{[x_0,x_1,x_2]}$\\
                    &                   & \tikzmark{12l} $f_{[x_1,x_2]}$ \tikzmark{12r} & \\
                    $x_2$   & $f_{[x_2]} = y_2$ \tikzmark{2}  &                  & \\
                    $\vdots$&                   &                                & \\
                \end{tabular}
            \end{center}
            \begin{tikzpicture}[overlay,remember picture,shorten >=5pt,shorten <=1pt]
                \draw [->] ({pic cs:0}) -- ({pic cs:01l});
                \draw [->] ({pic cs:1}) -- ({pic cs:01l});
                \draw [->] ({pic cs:1}) -- ({pic cs:12l});
                \draw [->] ({pic cs:2}) -- ({pic cs:12l});
                \draw [->] ({pic cs:01r}) -- ({pic cs:012});
                \draw [->] ({pic cs:12r}) -- ({pic cs:012});
            \end{tikzpicture}
            \begin{equation*}
                f_{[x_j,\dots,x_{k+j}]} = \dfrac{f_{[x_{j+1} \dots, x_{j+k}]} - f_{[x_{j} \dots, x_{j+k-1}]}}{x_{j+k} - x_j} = \dfrac{f_{\text{unten}} - f_{\text{oben}}}{x_{\text{unten}} - x_{\text{oben}}}
            \end{equation*}
            um dann Polynom zu berechnen
            \begin{equation*}
                p_n(x) = \gamma_0 + \sum_{i=1}^{n} \gamma_i (x-x_0) \dots (x-x_{i-1}) \tag*{$, \gamma_i = f_{[x_0 \dots x_i]}$}
            \end{equation*}
            wobei die $\gamma_i$'s einfach die oberste Zeile (ohne $x_0$) im Schema ist.\\
            \\
            \textbf{Hinweis:} Man kann Zeilen vertauschen. Das heißt wenn viele $f_{[x]} = 0$ lohnt es sich meist diese nach oben zu tauschen.\\
    \\ %TODO format Fehlerabschätzung (break between interpolation & errorCalc)
            \textbf{Fehlerabschätzung:}\\
            Äquidistant
            \begin{equation*}
                \max_{x \in [a,b]} |f(x) - p_n(x)| \leq \max_{x \in [a,b]} \dfrac{|f^{(n+1)}(x)|}{(n+1)!}(b-a)^{n+1}
            \end{equation*}
            Tschebyschev-Abszissen
            \begin{equation*}
                \max_{x \in [a,b]} |f(x) - p_n(x)| \leq \max_{x \in [a,b]} \dfrac{|f^{(n+1)}(x)|}{(n+1)!}\left(\dfrac{b-a}{2}\right)^{n+1}2^{-n}
            \end{equation*}

        %TODO \subsection{Spline-Interpolation}
%            \begin{definition}
%                Eine Splinefunktion der Ordnung $k$ zur Zerlegung $\Delta$ ist eine Funktion $s:[a,b]\rightarrow \mathbb{R}$ mit folgenden Eigenschaften:
%                \begin{itemize}
%                    \item es gilt $s \in C^{k-1}([a,b])$ (stetig diffbar)
%                    \item s stimmt auf jedem Intervall $[x_i,x_{i+1}]$
%                \end{itemize}
%                \textbf{Spline-Interpolation}: \\
%                Zu einer Zerlegung $\Delta = \{x_i:a = x_0 < x_1 < \dots < x_n = b\}$ und werten $y_i \in \mathbb{R}, i = 0, \dots, n$
%                bestimme $s \in S_{\Delta,k}$ mit
%                \begin{equation*}
%                    s(x_i) = y_i, i=0,...,n
%                \end{equation*}
%            \end{definition}
%            \subsubsection{Linear}
%            \begin{equation*}
%                s(x) = s_i(x) = \dfrac{x_{i+1} - x}{x_{i+1} - x_i} y_i + \dfrac{x - x_{i}}{x_{i+1} - x_i} y_{i+1} \mbox{ }\forall x \in [x_i, x_{i+1}]
%            \end{equation*}
%            mit Hilfsknoten $x_{-1} < a $ und $ x_{n+1} > b$ gilt dann
%            \begin{align*}
%                \varphi_i(x) =
%                \begin{cases}
%                    0 & \mbox{falls} x \leq x_{i-1}\\
%                    \dfrac{x - x_{i-1}}{x_{i} - x_{i-1}}& \mbox{falls} x \in [x_{i-1}, x_i]\\
%                    \dfrac{x_{i+1} - x}{x_{i+1} - x_i}& \mbox{falls} x \in [x_{i}, x_{i+1}]\\
%                    0 & \mbox{falls} x > x_{i+1}
%                \end{cases} \\
%                s(x) = \sum_{i=0}^n y_i \varphi_i(x), x \in [a,b]
%            \end{align*}
%            \begin{satz}
%                Zu einer Zerlegung $\Delta = \{x_i:a = x_0 < x_1 < \dots < x_n = b\}$ von $[a,b]$ und Werten $y_i$ existiert genau ein interpolierender Spline
%            \end{satz}
%            \begin{satz}
%                \begin{equation*}
%                    \max_{x \in [a,b]} |f(x) - s(x)| \leq \dfrac{1}{8} \max_{x \in [a,b]} | f''(x)| h_{\mbox{max}}^2
%                \end{equation*}
%            \end{satz}
%            \subsubsection{Kubisch}
%            \begin{equation*}
%                s_i(x) = \dfrac{1}{6} \left(
%                \dfrac{(x_{i+1} - x)^3}{x_{i+1} - x_i}M_i +
%                \dfrac{(x - x_{i})^3}{x_{i+1} - x_i}M_{i+1}
%                \right)
%                + c_i (x-x_i) + d_i
%            \end{equation*}
%            mit $h_i = x_{i+1} - x_i$
%            \begin{equation*}
%                \begin{matrix}
%                    d_i = y_i - \dfrac{h_i^2}{6}M_i & c_i = \dfrac{y_{i+1} - y_i}{h_i}- \dfrac{h_i}{6}(M_{i+1} - M_i)
%                \end{matrix}
%            \end{equation*}
%            \textbf{Natürliche Randbedingungen}:\\
%            \begin{equation*}
%                \begin{matrix}
%                    M_0 = M_n = 0 & b_0 = b_n = 0\\
%                    \lambda_0 = \lambda_n = 0 & \mu_0 = \mu_n = 1\\
%                \end{matrix}
%            \end{equation*}
%            \textbf{Hermite Randbedingungen}:\\
%            \begin{equation*}
%                \begin{matrix}
%                    b_0 = \dfrac{y_1-y_0}{h_0} - f'(a) & b_n = f'(b) - \dfrac{y_n - y_{n-1}}{h_{n-1}} & & \\
%                    \lambda_0 =\dfrac{h_0}{6} & \mu_0 = \dfrac{h_0}{3} & \lambda_n = \dfrac{h_{n-1}}{6} & \mu_n = \dfrac{h_{n-1}}{3}\\
%                \end{matrix}
%            \end{equation*}
%            \begin{equation*}
%                \begin{pmatrix}
%                    \mu_0 & \lambda_0 \\
%                    \frac{h_0}{6} & \frac{h_0 + h_1}{3} & \frac{h_1}{6}\\
%                    & \frac{h_1}{6} & \frac{h_1 + h_2}{3} & \frac{h_2}{6}\\
%                    & & \dots & \dots & \dots \\
%                    & &  & \lambda_n & \mu_n\\
%                \end{pmatrix}
%                \begin{pmatrix}
%                    M_0\\
%                    M_1\\
%                    M_2\\
%                    \dots\\
%                    M_n
%                \end{pmatrix}
%                =\begin{pmatrix}
%                     b_0\\
%                     \frac{y_2 - y_1}{h_1} - \frac{y_1-y_0}{h_0}\\
%                     \frac{y_3 - y_2}{h_2} - \frac{y_2-y_1}{h_1}\\
%                     \dots\\
%                     b_n
%                \end{pmatrix}
%            \end{equation*}
%            \setcounter{satz}{5}
%            \begin{satz}{Fehler Natürlich}
%                \begin{align*}
%                    |f(x) - s(x)| \leq \dfrac{h_{max}}{h_{min}} \sup_{\xi\in [a,b]} |f^{(4)}(\xi)| h^4_{max}\\
%                    |f^{(k)}(x) - s^{(k)}(x)| \leq \dfrac{2h_{max}}{h_{min}} \sup_{\xi\in [a,b]} |f^{(4)}(\xi)| h^{4-k}_{max}
%                \end{align*}
%            \end{satz}
%            \begin{satz}{Fehler Hermit}
%                \begin{align*}
%                    |f(x) - s(x)| \leq \dfrac{5}{384} \sup_{\xi\in [a,b]} |f^{(4)}(\xi)| h^4_{max}\\
%                    |f^{(k)}(x) - s^{(k)}(x)| \leq \dfrac{2h_{max}}{h_{min}} \sup_{\xi\in [a,b]} |f^{(4)}(\xi)| h^{4-k}_{max}
%                \end{align*}
%            \end{satz}

    \newpage
    \section{Numerische Integration}
        $a$, $b$ sind Start- und Endpunkt.
        $h$ ist die Schrittweite.
        $n$ sind die Stützstellen.
        \begin{equation*}
            \left\| f(\xi)\right\| = \max_{x \in [a,b] } | f(x)|
        \end{equation*}
        \subsection{Newton-Cotes}
            \textbf{Allgemeiner Fehler}
            \begin{equation*}
                \int_a^b \left\| f(x)  - p_n(x) \right\| dx \leq \dfrac{\left\| f^{(n+1)}(\xi)\right\|}{(n+1)!}(b-a)^{n+2}
                = \max_{x \in [a,b] } \dfrac{ | f^{(n+1)}(x)| }{(n+1)!}(b-a)^{n+2}
            \end{equation*}
            \subsubsection{geschlossen}
                \begin{align*}
                    x_i &= a+ih &  i&=0,\dots,n, &  h&=\frac{b-a}{n}
                \end{align*}
                \begin{equation*}
                    \begin{array}{c c c c c c c c c}
                        \hline\\[-.5\normalbaselineskip]
                        n & h & \multicolumn{5}{c}{\alpha_{i,n}}& E_n(f) & \text{Name}\\
                        \hline\\
                        1 & b-a & \frac{1}{2} & \frac{1}{2} & & & & \frac{-f^{(2)}(\xi)}{12}h^3 & \text{Trapezregel}\\
                        2 & \frac{b-a}{2} & \frac{1}{3} & \frac{4}{3} & \frac{1}{3} & & & \frac{-f^{(4)}(\xi)}{90}h^5 & \text{Simpson-Regel}\\
                        3 & \frac{b-a}{3} & \frac{3}{8} & \frac{9}{8} & \frac{9}{8} & \frac{3}{8} & & \frac{-3f^{(4)}(\xi)}{80}h^5 & \text{3/8-Regel}\\
                        4 & \frac{b-a}{4} & \frac{14}{45} & \frac{64}{45} & \frac{24}{45} & \frac{64}{45} & \frac{14}{45} & \frac{-8f^{(6)}(\xi)}{945}h^7 & \text{Milne-Regel}\\
                    \end{array}
                \end{equation*}
                \begin{equation*}
                    I_n(f) = h \sum^n_{i=0} \alpha_{i,n} f(x_i)
                \end{equation*}
            \subsubsection{offen}
                \begin{align*}
                    x_i &= a+ih &  i&=1,\dots,n+1, &  h&=\frac{b-a}{n+2}
                \end{align*}
                \begin{equation*}
                    \begin{array}{c c c c c c c}
                        \hline\\[-.5\normalbaselineskip]
                        n & h & \multicolumn{3}{c}{\tilde{\alpha}_{i,n}}& \tilde{E}_n (f) & \text{Name}\\
                        \hline\\
                        0 & \frac{b-a}{2} & 2 & & & \frac{f^{(2)}(\xi)}{3}h^3 & \text{Rechteckregel}\\
                        1 & \frac{b-a}{3} & \frac{3}{2} & \frac{3}{2} & & \frac{3f^{(2)}(\xi)}{4}h^3 & \text{Rechteckregel}\\
                        2 & \frac{b-a}{4} & \frac{8}{3} & -\frac{4}{3} & \frac{8}{3} & \frac{28f^{(4)}(\xi)}{90}h^5 & \text{Rechteckregel}\\
                    \end{array}
                \end{equation*}
                \begin{equation*}
                    \tilde{I}_n(f) = h \sum^{n+1}_{i=1} \tilde{\alpha}_{i,n} f(x_i)
                \end{equation*}
        \subsection{summiert}
            Aufteilen in Teilintervalle $m$
            \begin{align*}
                N &= n \cdot m & H&= \dfrac{b-a}{m} & h&= \dfrac{b-a}{N}\\
                x_i &=  a + ih & i&= 0,\dots, N
            \end{align*}

            \textbf{Summierte Trapezregel}\\
            (geschlossen, $n=1$, $h  = \frac{b-a}{m}$)
            \begin{equation*}
                S^{(1)}_N(f) = \dfrac{h}{2} \sum_{j=0}^{m-1}(f(x_j) + f(x_{j+1}))
            \end{equation*}
            Fehler: $R^{(1)}_N(f)=-\dfrac{f''(\xi)}{12}(b-a)h^2$\\[2ex]


            \textbf{Summierte Simpson-Regel}\\
            (geschlossen, $n = 2$, $h=\frac{b-a}{2m}$)
            \begin{equation*}
                S^{(2)}_N(f)=\dfrac{h}{3}\sum^{m-1}_{j=0}(f(x_{2j}) + 4f(x_{2j+1}) + f(x_{2j+2}))
            \end{equation*}
            Fehler: $R^{(2)}_N(f)=-\frac{f^{(4)}(\xi)}{180}(b-a)h^4$\\[2ex]

            \textbf{Summierte Rechteck-Regel}\\
            (offen, $n=0$, $2m = N$, $h = \frac{b-a}{N}$)
            \begin{equation*}
                \tilde{S}_N^{(0)} = 2h \sum^m_{j=1} f(x_{2j-1})
            \end{equation*}
            Fehler: $\tilde{R}^{(0)}_N(f)= \frac{f''(\xi)}{6}(b-a)h^2$

    \newpage
    \stepcounter{section}%TODO \subsection{Anfangswertprobleme}
    \section{Lineare Gleichungssysteme}
        \stepcounter{subsection}
        \stepcounter{subsection}
        \subsection{Cholesky Verfahren\hspace{1em}($LL^T = A$)}
            Für $j= 1,\dots ,n$
            \begin{equation*}
                l_{jj} =\sqrt{a_{jj}-\sum^{j-1}_{k=1}l_{jk}^2}
            \end{equation*}
            Falls Wurzel nicht existiert, STOPP $\Rightarrow A$ nicht definit\\
            \\
            \hspace{20mm} Für $i=j+1,\dots,n:$
            \begin{equation*}
                l_{ij} = \dfrac{a_{ij}-\Sigma_{k=1}^{j-1}l_{ik}l_{jk}}{l_{jj}}
            \end{equation*}
        \subsection{Fehlerabschätzung für gestörte Gleichungssysteme}
            \begin{align*}
                Ax = b && (A+ \Delta A)\tilde{x} = b + \Delta b
            \end{align*}
            dann gilt für den Fehler
            \begin{equation*}
                \dfrac{||\tilde{x} - x||}{||x||} \leq \dfrac{cond(A)}{1-cond(A)||\Delta A|| / ||A||} \left(\dfrac{||\Delta A||}{||A||} + \dfrac{|| \Delta b||}{||b||}\right)
            \end{equation*}
            mit
            \begin{align*} %TODO convert to table or something
                ||x||_2 &= \sqrt{x^Tx} & \text{induziert} &&||A||_2 &= \sqrt{\lambda_{max}(A^TA)}\\
                ||x||_1 &= \sum^n_{i=1}|x_i| & \text{induziert} && ||A||_1 &= \max_{j=1,\dots,n} \sum^n_{i=1} |a_{ij}| & \text{(Spaltensummen Norm = ``größte'' Spalte)}\\
                ||x||_\infty &= \max_{i=1,\dots,n}|x_i| & \text{induziert} && ||A||_\infty &= \max_{i=1,\dots,n} \sum^n_{j=1} |a_{ij}| & \text{(Zeilensummen Norm = ``größte'' Zeile)}\\
            \end{align*}
            \begin{equation*}
                cond(A) = ||A||\mbox{ }||A^{-1}||
            \end{equation*}

    \newpage
    \section{Nichtlineare Gleichungssysteme}
        \stepcounter{subsection}
        \stepcounter{subsection}
            \subsubsection{lokales Newton-Verfahren}
                \begin{align*}
                    s^{(k)} \text{ Lösung von } J_F(x^{(k)})s^{(k)} &= - F(x^{(k)})\\
                    x^{(k+1)} &= x^{(k)} + s^{(k)}
                \end{align*}
                Bei $f(x) : \mathbb{R}^1\rightarrow\mathbb{R}^1$
                \begin{equation*}
                    J_{F}(x^{(k)})^{-1} = F'(x^{(k)})
                \end{equation*}
                \begin{align*}
                    \Rightarrow s^{(k)} = - \frac{F(x^{(k)})}{F'(x^{(k)})} &&
                    x^{(k+1)} = x^{(k)} - \frac{F(x^{(k)})}{F'(x^{(k)})}
                \end{align*}
%            \stepcounter{subsubsection}
%            \subsubsection{globales Newton-Verfahrens}
%                \textbf{Schrittweitenwahl nach Armijo}:\\
%                sei $\delta \in ]0, \frac{1}{2}[$ (z.B. $10^{-3}$) fest gegeben.
%                Wähle das Größte $\sigma_k \in \{1, \frac{1}{2}, \frac{1}{4}, \dots\}$ mit
%                \begin{equation*}
%                    ||F(x^{(k)} + \sigma_k s^{(k)})||_2^2 \leq ||F(x^{(k)})||_2^2-2\delta \sigma_k ||F(x^{(k)})||_2^2
%                \end{equation*}
%                \begin{satz}
%                    Algo für das Globalisierte Newton-Verfahren:
%                    \begin{enumerate}
%                        \item Falls $F(x^{(k)}) = 0$ STOPP mit Ergebnis $x^{(k)}$
%                        \item Berechne $s^{(k)}$
%                        \item Bestimme $\sigma_k$ nach Armijo
%                        \item $x_{k+1} = x^{(k)} + \sigma_ks^{(k)}$
%                    \end{enumerate}
%                \end{satz}
    \newpage
    \section{Verfahren zur Eigenwert- und Eigenvektorberechnung}
        \stepcounter{subsection}
        \subsection{Vektoriteration}
            \textbf{Einfache Vektoriteration nach von Mises:}\\
            Wir setzen die zu Iterationsmatrix $B$ einfach gleich der gegebenen Matrix $A$
            \begin{equation*}
                B = A
            \end{equation*}
            Um die nächste Iteration von $z$ zu bekommen bedarf es nur dieser Formel, welche man die ganze so lange durchiteriert, bis man bei der gewünschen Zahl angekommen ist.
            \begin{equation*}
                z^{(k+1)} = \dfrac{1}{||Bz^{(k)}||}Bz^{(k)}
            \end{equation*}
            Um nun den Rayleigh-Quotienten von einem beliebigen $k$ (meistens wird das vorletzte benutzt) einfach alles in die Formel einsetzen.
            \begin{equation*}
                R(z^{(k)},B)=\dfrac{(z^{(k)})^H Bz^{(k)}}{(z^{(k)})^Hz^{(k)}}
            \end{equation*}
            Bei reellen Werten entspricht $(.)^H$ der Transponierten.\\
            \\
            \textbf{Inverse Vektoriteration von Wielandt:}\\
            Hier ist $B$ mit einem Shift $\mu$ verschoben, und das Ganze invertiert.
            \begin{equation*}
                B = (A-\mu I)^{-1}
            \end{equation*}
            \textbf{Achtung!} Dabei nicht die Inverse bestimmen, sondern über die DGL
            \begin{equation*}
                (A-\mu I)\hat{z}^{(k+1)} = z^{(k)}\\
            \end{equation*}
            $\hat{z}^{k+1}$ bestimmen und dann normieren zu
            \begin{equation*}
                z^{(k+1)} = \dfrac{\hat{z}^{(k+1)}}{||\hat{z}^{(k+1)}||}
            \end{equation*}
            Um nun den Rayleigh-Quotienten von einem beliebigen $k$ (meistens wird das vorletzte benutzt) einfach alles in die Formel einsetzen.
            \begin{equation*}
                R(z^{(k)}, (A - \mu I)^{-1}) = \dfrac{(z^{(k)})^H\hat{z}^{(k+1)}}{(z^{(k)})^Hz^{(k)}}
            \end{equation*}
            Bei reellen Werten entspricht $(.)^H$ der Transponierten.\\
            Einen Eigenwert $\lambda_i$ (oder Schätzung) erhalten wir dann durch Umstellen von
            \begin{equation*}
                \mu_i = \dfrac{1}{\lambda_i - \mu}
            \end{equation*}
            Wobei $\mu_i$ dem Rayleigh-Quotienten entspricht.
    \newpage
    \stepcounter{section}
    \section{Schätzverfahren und Konfidenzintervalle}
        \stepcounter{subsection}
        \subsection{Maximum-Likelihood-Schätzer}
            $f_\theta(x)$ entspricht der Dichtefunktion. Bei diskreten Werten siehe oben.
            \begin{align*}
                L(\theta; x_1, \dots x_n) &= f_\theta(x_1)f_\theta(x_2)\dots f_\theta(x_n)\\
                ln\left( L(\theta; x_1, \dots x_n) \right) &= \sum_{i=1}^{n}ln\left( f_\theta(x_i) \right)
            \end{align*}
            Teilweise kann man $f_\theta$ durch den $ln$ nochmal in Summen aufteilen, da dann alle Summanden ohne $\theta$ bei der Ableitung rausfliegen.
            \begin{equation*}
                \frac{\partial}{\partial \theta} ln\left( L(\theta; x_1, \dots x_n) \right) =
                \frac{\partial}{\partial \theta} \sum_{i=1}^{n}ln\left( f_\theta(x_i) \right) \overset{!}{=} 0
            \end{equation*}
            Nun nach $\theta$ umstellen. Dies ist dann die eindeutige Nullstelle
            \begin{equation*}
                \hat{\theta}(x_1, \dots, x_n) = \dots
            \end{equation*}
            Um zu wissen, dass es ein Maximum ist, muss man noch schauen ob die 2. Ableitung $<0$ ist
            \begin{equation*}
                \frac{\partial^2}{\partial \theta^2} ln\left( L(\theta; x_1, \dots x_n) \right) \overset{!}{<} 0
            \end{equation*}
        \subsection{Konfidenzintervalle}
        %TODO add decision tree and maybe tests into table to compact them
            \begin{align*}
                F_\theta(x) &= F_{(\mu, \sigma^2)}(x)= \Phi(\dfrac{x-\mu}{\sigma}) &
                \bar{X}_{(n)}&=\dfrac{1}{n}\sum_{i=1}^n X_i &
                S^2_{(n)} &= \dfrac{1}{n-1}\sum_{i=1}^n (X_i - \bar{X}_{(n)})^2
            \end{align*}
            $\Theta = \{(\mu, \sigma^2_0):\mu \in \mathbb{R},\sigma^2 > 0\}$ und $\tau(\theta) = \mu/\sigma^2$.
            Das Konfidenzintervall für $\mu/\sigma^2$ zum Niveau $1-\alpha$ lautet
            \subsubsection*{Konfidenzintervall für $\mu$ bei bekannter Varianz $\sigma^2 = \sigma_0^2$}
            \begin{equation*}
                I(X_1,\dots,X_n)=\left[
                \bar{X}_{(n)}-u_{1-\alpha/2}\dfrac{\sigma_0}{\sqrt{n}}
                ,
                \bar{X}_{(n)}+u_{1-\alpha/2}\dfrac{\sigma_0}{\sqrt{n}}
                \right]
            \end{equation*}

            \subsubsection*{Konfidenzintervall für $\mu$ bei unbekannter Varianz $\sigma^2$}
            \begin{equation*}
                I(X_1,\dots,X_n)=\left[
                \bar{X}_{(n)}-t_{n-1;1-\alpha/2}\sqrt{\dfrac{S^2_{(n)}}{n}}
                ,
                \bar{X}_{(n)}+t_{n-1;1-\alpha/2}\sqrt{\dfrac{S^2_{(n)}}{n}}
                \right]
            \end{equation*}
            \subsubsection*{Konfidenzintervall für $\sigma^2$ bei bekanntem Erwartungswert $\mu = \mu_0$}
            \begin{equation*}
                I(X_1,\dots,X_n)=\left[
                \dfrac{\Sigma_{i=1}^n (X_i-\mu_0)^2}{\chi^2_{n;1-\alpha/2}}
                ,
                \dfrac{\Sigma_{i=1}^n (X_i-\mu_0)^2}{\chi^2_{n;\alpha/2}}
                \right]
            \end{equation*}
            \subsubsection*{Konfidenzintervall für $\sigma^2$ bei unbekanntem Erwartungswert $\mu$}
            \begin{equation*}
                I(X_1,\dots,X_n)=\left[
                \dfrac{(n-1)S^2_{(n)}}{\chi^2_{n-1;1-\alpha/2}}
                ,
                \dfrac{(n-1)S^2_{(n)}}{\chi^2_{n-1;\alpha/2}}
                \right]
            \end{equation*}
    \newpage
    \section{Tests}
    %TODO add decision tree and maybe tests into table to compact them
        \begin{enumerate}
            \item $X_1,\dots,X_n$ unabhängig, identisch $N(\mu, \sigma^2)$-verteilt
        \end{enumerate}
        \subsubsection*{Gauß-Test , testen für $\mu$ bei bekannter Varianz $\sigma^2 = \sigma_0^2$}
            \begin{enumerate}
                \stepcounter{enumi}
                \item a) $H_0: \mu = \mu_0$, b) $H_0: \mu \leq \mu_0$, c) $H_0: \mu \geq \mu_0$
                \item Testgröße
                \begin{equation*}
                    T(X_1,\dots,X_n)=\dfrac{\sqrt{n}}{\sigma_0}(\bar{X}_{(n)}-\mu_0)
                \end{equation*}
                \item Ablehnung Falls\\
                a) $|T| > u_{1-\alpha/2}$, b) $T > u_{1-\alpha}$, c) $T < u_{\alpha}$
            \end{enumerate}
        \subsubsection*{t-Test , testen für $\mu$ bei unbekannter Varianz $\sigma^2$}
            \begin{enumerate}
                \stepcounter{enumi}
                \item a) $H_0: \mu = \mu_0$, b) $H_0: \mu \leq \mu_0$, c) $H_0: \mu \geq \mu_0$
                \item Testgröße
                \begin{equation*}
                    T(X_1,\dots,X_n)=\sqrt{n}\dfrac{\bar{X}_{(n)}-\mu_0}{\sqrt{S_{(n)}^2}}
                \end{equation*}
                \item Ablehnung Falls\\
                a) $|T| > t_{n-1;1-\alpha/2}$, b) $T > t_{n-1;1-\alpha}$, c) $T < t_{n-1;\alpha}$
            \end{enumerate}
        \subsubsection*{$\chi^2$-Streuungstest , testen für $\sigma^2$ bei unbekanntem Erwartungswert $\mu$}
            \begin{enumerate}
                \stepcounter{enumi}
                \item a) $H_0: \sigma^2 = \sigma^2_0$, b) $H_0: \sigma^2 \leq \sigma^2_0$, c) $H_0: \sigma^2 \geq \sigma^2_0$
                \item Testgröße
                \begin{equation*}
                    T(X_1,\dots,X_n)=\dfrac{(n-1)}{\sigma^2_0}S^2_{(n)}
                \end{equation*}
                \item Ablehnung falls\\
                a) $T<\chi^2_{n-1;\alpha/2}$ oder $T>\chi^2_{n-1;1-\alpha/2}$,
                b) $T>\chi^2_{n-1;1-\alpha}$,
                c) $T<\chi^2_{n-1;\alpha}$
            \end{enumerate}

\end{document}